{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ld1aLmfRmeog"
      },
      "outputs": [],
      "source": [
        "# installing the sentence-transformers library\n",
        "#Itâ€™s widely used for sentence embeddings, semantic similarity, clustering, etc.\n",
        "!pip install -U sentence-transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to read and manipulate the data\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "pd.set_option('max_colwidth', None)    # setting column to the maximum column width as per the data\n",
        "\n",
        "# to visualise data\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# to compute distances\n",
        "from scipy.spatial.distance import cdist, pdist\n",
        "from sklearn.metrics import silhouette_score\n",
        "\n",
        "# importing the PyTorch Deep Learning library\n",
        "import torch\n",
        "\n",
        "# to import the model\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# to cluster the data\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# to compute metrics\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# to avoid displaying unnecessary warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "r4xZ5QhTmllP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "h00M5DBQm4Rz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "d9E8C5CGnStB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reviews = pd.read_csv(\"/content/news_articles.csv\")"
      ],
      "metadata": {
        "id": "fBBcJyXRnrgt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = reviews.copy()"
      ],
      "metadata": {
        "id": "YRMppqG_n5jz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[1,'Text']"
      ],
      "metadata": {
        "id": "4-w6BfTloHai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head()"
      ],
      "metadata": {
        "id": "PxTonA1AoNOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.loc[3,'Text']"
      ],
      "metadata": {
        "id": "DZJ3TqPxoQRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail()"
      ],
      "metadata": {
        "id": "rdOP3HqEoYU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "PxZ_lXYCogPX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "8M1Y4-2eoj5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "pwgoI8Quopoe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = data.drop_duplicates()\n",
        "\n",
        "# resetting the dataframe index\n",
        "data.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "mJIsV5FtowwS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.duplicated().sum()"
      ],
      "metadata": {
        "id": "NqPDTAHco1Ok"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "gP2HwotSo6IQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" hf_xet is a helper package for enhancing file transfers with the Hugging Face Hub.\n",
        "It integrates Rust-based code for efficient, chunk-based deduplication,\n",
        "and caching when uploading or downloading large files\"\"\"\n",
        "!pip install hf_xet"
      ],
      "metadata": {
        "id": "OjuJLPVdo9G9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "#Defining the model\n",
        "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n"
      ],
      "metadata": {
        "id": "zGVuvHVGpCrz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting the device to GPU if available, else CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "embedding_matrix = model.encode(data['Text'], show_progress_bar=True, device=device)\n",
        "embedding_matrix.shape"
      ],
      "metadata": {
        "id": "bz0kq0I0pLBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encoding the dataset\n",
        "embedding_matrix = model.encode(data['Text'], show_progress_bar=True, device=device)"
      ],
      "metadata": {
        "id": "5R0P5pgGpTFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the shape of the embedding matrix\n",
        "embedding_matrix.shape"
      ],
      "metadata": {
        "id": "EGgPEOrAphP8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# printing the embedding vector of the first review in the dataset\n",
        "len(embedding_matrix[0])"
      ],
      "metadata": {
        "id": "jrSexXVxpnOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "a= \"i love apple\"\n",
        "b= \"apple is a fruit\"\n",
        "c= \"i like this table\"\n"
      ],
      "metadata": {
        "id": "mAApI2T4pqvj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to compute the cosine similarity between two embedding vectors\n",
        "def cosine_score(text1,text2):\n",
        "    # encoding the text\n",
        "    embeddings1 = model.encode(text1)\n",
        "    embeddings2 = model.encode(text2)\n",
        "\n",
        "    # calculating the L2 norm of the embedding vector\n",
        "    norm1 = np.linalg.norm(embeddings1)\n",
        "    norm2 = np.linalg.norm(embeddings2)\n",
        "\n",
        "    # computing the cosine similarity\n",
        "    cosine_similarity_score = ((np.dot(embeddings1,embeddings2))/(norm1*norm2))\n",
        "\n",
        "    return cosine_similarity_score"
      ],
      "metadata": {
        "id": "lw1eIJ06quvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cosine_score(a,b))\n",
        "print(cosine_score(b,c))\n",
        "print(cosine_score(a,c))"
      ],
      "metadata": {
        "id": "FSKmyLDdqy1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ussing prebuilt method\n",
        "from sentence_transformers import util\n",
        "\n",
        "embeddings1 = model.encode(a)\n",
        "embeddings2 = model.encode(b)\n",
        "embeddings3 = model.encode(c)\n",
        "\n",
        "print(util.cos_sim(embeddings1, embeddings2))\n",
        "print(util.cos_sim(embeddings2, embeddings3))\n",
        "print(util.cos_sim(embeddings1, embeddings3))"
      ],
      "metadata": {
        "id": "O6xcPd5Oq2Ek"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining a function to find the top k similar sentences for a given query\n",
        "def top_k_similar_sentences(embedding_matrix, query_text, k):\n",
        "    # encoding the query text\n",
        "    query_embedding = model.encode(query_text)\n",
        "\n",
        "    # calculating the cosine similarity between the query vector and all other encoded vectors of our dataset\n",
        "    score_vector = np.dot(embedding_matrix,query_embedding)\n",
        "\n",
        "    # sorting the scores in descending order and choosing the first k\n",
        "    top_k_indices = np.argsort(score_vector)[::-1][:k]\n",
        "\n",
        "    # returning the corresponding reviews\n",
        "    return data.loc[list(top_k_indices), 'Text']"
      ],
      "metadata": {
        "id": "y7ER8JoorACk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the query text\n",
        "query_text = \"Budget for elections\"\n",
        "\n",
        "# displaying the top 3 similar sentences\n",
        "top_k_reviews = top_k_similar_sentences(embedding_matrix, query_text, 3)\n",
        "\n",
        "for i in top_k_reviews:\n",
        "    print(i, end=\"\\n\")\n",
        "    print(\"*******************************************************************\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "Als-5uHfrHbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the query text\n",
        "query_text = \"High imports and exports\"\n",
        "\n",
        "# displaying the top 3 similar sentences\n",
        "top_k_reviews = top_k_similar_sentences(embedding_matrix, query_text, 3)\n",
        "\n",
        "for i in top_k_reviews:\n",
        "    print(i, end=\"\\n\")\n",
        "    print(\"*******************************************************************\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "WjLvgqZrrMel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "meanDistortions = []\n",
        "clusters = range(2, 11)\n",
        "\n",
        "for k in clusters:\n",
        "    clusterer = KMeans(n_clusters=k, random_state=1)\n",
        "    clusterer.fit(embedding_matrix)\n",
        "\n",
        "    prediction = clusterer.predict(embedding_matrix)\n",
        "\n",
        "    distortion = sum(\n",
        "        np.min(cdist(embedding_matrix, clusterer.cluster_centers_, \"euclidean\"), axis=1) ** 2\n",
        "    )\n",
        "    meanDistortions.append(distortion)\n",
        "\n",
        "    print(\"Number of Clusters:\", k, \"\\tAverage Distortion:\", distortion)"
      ],
      "metadata": {
        "id": "3iY9C-r1rZzV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(clusters, meanDistortions, \"bx-\")\n",
        "plt.xlabel(\"k\")\n",
        "plt.ylabel(\"Average Distortion\")\n",
        "plt.title(\"Selecting k with the Elbow Method\", fontsize=20)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HTX0ivWuriyS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sil_score = []\n",
        "cluster_list = range(2, 10)\n",
        "\n",
        "for n_clusters in cluster_list:\n",
        "    clusterer = KMeans(n_clusters=n_clusters, random_state=1)\n",
        "\n",
        "    preds = clusterer.fit_predict((embedding_matrix))\n",
        "\n",
        "    score = silhouette_score(embedding_matrix, preds)\n",
        "    sil_score.append(score)\n",
        "\n",
        "    print(\"For n_clusters = {}, the silhouette score is {})\".format(n_clusters, score))"
      ],
      "metadata": {
        "id": "5UA_H4qyrvXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(cluster_list, sil_score, \"bx-\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wq3hyO9Mr1-D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining the number of clusters/categories\n",
        "n_categories = 5\n",
        "\n",
        "# fitting the model\n",
        "kmeans = KMeans(n_clusters=n_categories, random_state=1).fit(embedding_matrix)"
      ],
      "metadata": {
        "id": "el7SgZGNr6ND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the cluster centers\n",
        "centers = kmeans.cluster_centers_\n",
        "centers"
      ],
      "metadata": {
        "id": "DCFx3psDr_Qy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a copy of the data\n",
        "clustered_data = data.copy()\n",
        "\n",
        "# assigning the cluster/category labels\n",
        "clustered_data['Category'] = kmeans.labels_\n",
        "\n",
        "clustered_data.head()"
      ],
      "metadata": {
        "id": "-LNG4M1dsDjv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for each cluster, printing the 5 random news articles\n",
        "for i in range(5):\n",
        "    print(\"CLUSTER\",i)\n",
        "    print(clustered_data.loc[clustered_data.Category == i, 'Text'].sample(5, random_state=1).values)\n",
        "    print(\"*****************************************************************\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "lzVSZQGRsHu1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dictionary of cluster label to category\n",
        "category_dict = {\n",
        "    0: 'Sports',\n",
        "    1: 'Politics',\n",
        "    2: 'Entertainment',\n",
        "    3: 'Business',\n",
        "    4: 'Technology'\n",
        "}\n",
        "# mapping cluster labels to categories\n",
        "clustered_data['Category'] = clustered_data['Category'].map(category_dict)\n",
        "\n",
        "clustered_data.head()"
      ],
      "metadata": {
        "id": "8vUETv22sNcz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "id": "GbPg02OYsbNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading the actual labels\n",
        "labels = pd.read_csv(\"news_article_labels.csv\")"
      ],
      "metadata": {
        "id": "0dXX2oUds4bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels.shape"
      ],
      "metadata": {
        "id": "ntJrX9rus8JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# checking the unique labels\n",
        "labels['Label'].unique()"
      ],
      "metadata": {
        "id": "bLE-tj2VtADW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# adding the actual categories to our dataframe\n",
        "clustered_data['Actual Category'] = labels['Label'].values"
      ],
      "metadata": {
        "id": "apbzXbOUtERH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(clustered_data['Actual Category'], clustered_data['Category']))"
      ],
      "metadata": {
        "id": "Kh8MHhLatHlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a dataframe of incorrect categorizations\n",
        "incorrect_category_data = clustered_data[clustered_data['Actual Category'] != clustered_data['Category']].copy()\n",
        "incorrect_category_data.shape"
      ],
      "metadata": {
        "id": "L-3_kg7btLZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "incorrect_category_data.head()"
      ],
      "metadata": {
        "id": "rTGvde9otPaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 24\n",
        "\n",
        "print('Distance from Actual Category')\n",
        "print(cdist(embedding_matrix[idx].reshape(1,-1), kmeans.cluster_centers_[[2]], \"euclidean\")[0,0])\n",
        "\n",
        "print('Distance from Predicted Category')\n",
        "print(cdist(embedding_matrix[idx].reshape(1,-1), kmeans.cluster_centers_[[3]], \"euclidean\")[0,0])"
      ],
      "metadata": {
        "id": "K6Wc4c4YtS_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = 45\n",
        "\n",
        "print('Distance from Actual Category')\n",
        "print(cdist(embedding_matrix[idx].reshape(1,-1), kmeans.cluster_centers_[[2]], \"euclidean\")[0,0])\n",
        "\n",
        "print('Distance from Predicted Category')\n",
        "print(cdist(embedding_matrix[idx].reshape(1,-1), kmeans.cluster_centers_[[4]], \"euclidean\")[0,0])"
      ],
      "metadata": {
        "id": "3fOxTI0ktZe-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}